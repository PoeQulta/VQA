# Visual Question Answering on the VizWiz Dataset

This repository contains the implementation of the paper Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model. The model leverages OpenAI's CLIP model to encode both text and images.

## Table of Contents
- Introduction
- Results

## Introduction
The project aims to implement a Visual Question Answering (VQA) model on the VizWiz dataset. The model is based on the paper "Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model". It uses OpenAI's CLIP model to encode both text and images, which are then used to answer questions about the images.

## Results
The Results match that of the paper referenced above --Edit Later --
